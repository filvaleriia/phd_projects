{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2268d44",
   "metadata": {},
   "source": [
    "## Priprava dat\n",
    "Rozdeleni dat na testovaci a trenovaco sety: 5krat aby byli co nejvic priblizene k sobe scaffoldy a 5krat aby byli co nejvic vzdalene od sebe scaffoldy\n",
    "\n",
    "### Molpher\n",
    "Pro Molpher budou vzaty jen uniaktni csk, takze pak kazdemu unaktnimu scaffoldu bude prirazena nejvic aktivnjesi sloucenina\n",
    "\n",
    "### Other generators\n",
    "Pro ostatni generatory budou vzaty vsechny slouceniny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8a669",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b23a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Scaffolds.MurckoScaffold import GetScaffoldForMol\n",
    "from rdkit.Chem.Scaffolds.MurckoScaffold import MakeScaffoldGeneric\n",
    "from rdkit.Chem.Scaffolds.MurckoScaffold import MurckoScaffoldSmiles\n",
    "from rdkit.DataManip.Metric import GetTanimotoDistMat\n",
    "from rdkit.DataManip.Metric import GetTanimotoSimMat\n",
    "from rdkit.Chem import DataStructs\n",
    "from rdkit.ML.Cluster import Butina\n",
    "from rdkit.ML.Cluster.Butina import EuclideanDist\n",
    "from rdkit.ML.KNN.DistFunctions import TanimotoDist\n",
    "from rdkit.DataStructs.cDataStructs import BulkTanimotoSimilarity\n",
    "\n",
    "#descripts\n",
    "from rdkit.Chem import Lipinski\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "from rdkit.Chem.Lipinski import NumAromaticHeterocycles\n",
    "from rdkit.Chem.Lipinski import NumAliphaticRings\n",
    "from rdkit.Chem.Lipinski import NumAromaticHeterocycles\n",
    "from rdkit.Chem.Lipinski import NumAromaticRings\n",
    "\n",
    "from rdkit.Chem.SaltRemover import SaltRemover\n",
    "\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn import manifold\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# plots\n",
    "from matplotlib import pyplot\n",
    "import seaborn\n",
    "\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b208c07",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f65b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkce pro opravu problemu z SF5- prevede na CF3\n",
    "#funkce od Wima\n",
    "rxn = AllChem.ReactionFromSmarts\\\n",
    "('[*:0][S:1]([F:2])([F:3])([F:4])([F:5])[F:6]>>[*:0]-[C](-[F])(-[F])-[F].[*:1]([*:2])([*:3])([*:4])([*:5])[*:6]')\n",
    "def MakeScaffoldGeneric_fixed(mol):\n",
    "    for i in range(len(mol.GetSubstructMatches(Chem.MolFromSmiles(\"S(F)(F)(F)(F)F\")))):\n",
    "        products = rxn.RunReactants((mol,)) # tuple\n",
    "        if len(products)>0:\n",
    "            mol = products[0][0]\n",
    "    return MakeScaffoldGeneric(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3819a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_processing_data(name_file,name):\n",
    "\n",
    "    dff = pd.read_csv(f\"chembl_data/sets/{name_file}/{name}\",header=None)\n",
    "    dff.columns =['molregno', 'stand_type', \n",
    "                                    'pchembl_value', 'stand_value',\n",
    "                                    'canonical_smiles', 'stand_inchi',\n",
    "                                   'chembl_id', 'tid','pref_name']\n",
    "            \n",
    "\n",
    "    dff['scaffolds_csk'] = [1 for x in range(len(dff))]\n",
    "    delete_element = 0\n",
    "    for x in range(len(dff)):\n",
    "                #print(x)\n",
    "        remover = SaltRemover()\n",
    "        res = remover.StripMol(Chem.MolFromSmiles(dff['canonical_smiles'][x]))\n",
    "        dff['canonical_smiles'][x] = Chem.MolToSmiles(res)\n",
    "        if NumAromaticRings(Chem.MolFromSmiles(dff['canonical_smiles'][x])) == 0 and\\\n",
    "            NumAliphaticRings(Chem.MolFromSmiles(dff['canonical_smiles'][x])) == 0:\n",
    "            print(\"Not contain ring\")\n",
    "            print(dff['canonical_smiles'][x])\n",
    "            display(Chem.MolFromSmiles(dff['canonical_smiles'][x]))\n",
    "            dff = dff.drop([x])\n",
    "            delete_element = 1\n",
    "        if delete_element != 1:\n",
    "            try:\n",
    "                dff['scaffolds_csk'].loc[x] = MurckoScaffoldSmiles(\\\n",
    "                                         Chem.MolToSmiles(MakeScaffoldGeneric\\\n",
    "                                       (Chem.MolFromSmiles(dff['canonical_smiles'][x]))))\n",
    "            except:\n",
    "                print(\"Faild to create scaffold_csk\")\n",
    "                print(\"Index\",x)\n",
    "                print(dff['canonical_smiles'][x])\n",
    "                display(Chem.MolFromSmiles(dff['canonical_smiles'][x]))\n",
    "                try:\n",
    "                    mol = MakeScaffoldGeneric_fixed(Chem.MolFromSmiles(dff['canonical_smiles'][x]))\n",
    "                    display(mol)\n",
    "                    dff['scaffolds_csk'].loc[x] = MurckoScaffoldSmiles(Chem.MolToSmiles(mol))\n",
    "                    display(Chem.MolFromSmiles(MurckoScaffoldSmiles(Chem.MolToSmiles(mol))))\n",
    "                except:\n",
    "                    dff = dff.drop([x])\n",
    "        delete_element = 0\n",
    "        \n",
    "    #dff['mfp'] = [AllChem.GetMorganFingerprintAsBitVect\\\n",
    "    #          (Chem.MolFromSmiles(x), 3, nBits = 2048) for x in  dff['scaffolds_csk']]\n",
    "    dff['mfp'] = [(AllChem.GetMorganFingerprintAsBitVect\\\n",
    "                (Chem.MolFromSmiles(i),3, nBits=2048)) for i in dff['scaffolds_csk']]\n",
    "      \n",
    "    dff.reset_index(level=0, inplace=True)\n",
    "    dff = dff.drop(columns = ['index'])\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91d6754d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90275/1309756061.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dff['canonical_smiles'][x] = Chem.MolToSmiles(res)\n",
      "/tmp/ipykernel_90275/1309756061.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dff['scaffolds_csk'].loc[x] = MurckoScaffoldSmiles(\\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molregno</th>\n",
       "      <th>stand_type</th>\n",
       "      <th>pchembl_value</th>\n",
       "      <th>stand_value</th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>stand_inchi</th>\n",
       "      <th>chembl_id</th>\n",
       "      <th>tid</th>\n",
       "      <th>pref_name</th>\n",
       "      <th>scaffolds_csk</th>\n",
       "      <th>mfp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>557956</td>\n",
       "      <td>IC50</td>\n",
       "      <td>7.85</td>\n",
       "      <td>14.0</td>\n",
       "      <td>C[C@H]1C[C@@H]2[C@H]3CCC4=CC(=O)C=C[C@@]4(C)[C...</td>\n",
       "      <td>PENABDXTRKXMIW-PZVMULSCSA-N</td>\n",
       "      <td>CHEMBL540936</td>\n",
       "      <td>25</td>\n",
       "      <td>Glucocorticoid receptor</td>\n",
       "      <td>C(CCCCCCC1CCC2C1CCC1C3CCCCC3CCC21)CCCCCC1CCC(C...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1607842</td>\n",
       "      <td>IC50</td>\n",
       "      <td>8.70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CC[C@@H](Cn1ccc2ccccc21)NS(=O)(=O)c1c(N)cc(Cl)...</td>\n",
       "      <td>RXEIQMFFHIVGLD-AWEZNQCLSA-N</td>\n",
       "      <td>CHEMBL3093461</td>\n",
       "      <td>25</td>\n",
       "      <td>Glucocorticoid receptor</td>\n",
       "      <td>C1CCC(CCCCC2CCC3CCCCC23)CC1</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1841315</td>\n",
       "      <td>IC50</td>\n",
       "      <td>7.38</td>\n",
       "      <td>22.0</td>\n",
       "      <td>CC[C@@]12C[C@@](C)(O)[C@](O)(c3cccnc3)C[C@H]1C...</td>\n",
       "      <td>KDUBEHWLJHNXHQ-XUFNMVPLSA-N</td>\n",
       "      <td>CHEMBL3421877</td>\n",
       "      <td>25</td>\n",
       "      <td>Glucocorticoid receptor</td>\n",
       "      <td>C1CCC(C2CCC3C(CCC4CCCCC43)C2)CC1</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2172692</td>\n",
       "      <td>IC50</td>\n",
       "      <td>7.01</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Cc1cc(C)c(S(=O)(=O)N[C@@H](C)COc2ccc3c(cnn3-c3...</td>\n",
       "      <td>LREULHCSPAWXMB-IBGZPJMESA-N</td>\n",
       "      <td>CHEMBL3963321</td>\n",
       "      <td>25</td>\n",
       "      <td>Glucocorticoid receptor</td>\n",
       "      <td>C1CCC(CCCCCC2CCC3C(CCC3C3CCCCC3)C2)CC1</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>325089</td>\n",
       "      <td>IC50</td>\n",
       "      <td>8.29</td>\n",
       "      <td>5.1</td>\n",
       "      <td>C[C@]12Cc3cnn(-c4ccc(F)cc4)c3C=C1CCC[C@@H]2[C@...</td>\n",
       "      <td>GSBXDPQKEHNRQR-NPAAKHOSSA-N</td>\n",
       "      <td>CHEMBL363179</td>\n",
       "      <td>25</td>\n",
       "      <td>Glucocorticoid receptor</td>\n",
       "      <td>C1CCC(C2CCC3CC4C(CC5CCC6CCCCC65)CCCC4CC32)CC1</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   molregno stand_type  pchembl_value  stand_value  \\\n",
       "0    557956       IC50           7.85         14.0   \n",
       "1   1607842       IC50           8.70          2.0   \n",
       "2   1841315       IC50           7.38         22.0   \n",
       "3   2172692       IC50           7.01         98.0   \n",
       "4    325089       IC50           8.29          5.1   \n",
       "\n",
       "                                    canonical_smiles  \\\n",
       "0  C[C@H]1C[C@@H]2[C@H]3CCC4=CC(=O)C=C[C@@]4(C)[C...   \n",
       "1  CC[C@@H](Cn1ccc2ccccc21)NS(=O)(=O)c1c(N)cc(Cl)...   \n",
       "2  CC[C@@]12C[C@@](C)(O)[C@](O)(c3cccnc3)C[C@H]1C...   \n",
       "3  Cc1cc(C)c(S(=O)(=O)N[C@@H](C)COc2ccc3c(cnn3-c3...   \n",
       "4  C[C@]12Cc3cnn(-c4ccc(F)cc4)c3C=C1CCC[C@@H]2[C@...   \n",
       "\n",
       "                   stand_inchi      chembl_id  tid                 pref_name  \\\n",
       "0  PENABDXTRKXMIW-PZVMULSCSA-N   CHEMBL540936   25  Glucocorticoid receptor    \n",
       "1  RXEIQMFFHIVGLD-AWEZNQCLSA-N  CHEMBL3093461   25  Glucocorticoid receptor    \n",
       "2  KDUBEHWLJHNXHQ-XUFNMVPLSA-N  CHEMBL3421877   25  Glucocorticoid receptor    \n",
       "3  LREULHCSPAWXMB-IBGZPJMESA-N  CHEMBL3963321   25  Glucocorticoid receptor    \n",
       "4  GSBXDPQKEHNRQR-NPAAKHOSSA-N   CHEMBL363179   25  Glucocorticoid receptor    \n",
       "\n",
       "                                       scaffolds_csk  \\\n",
       "0  C(CCCCCCC1CCC2C1CCC1C3CCCCC3CCC21)CCCCCC1CCC(C...   \n",
       "1                        C1CCC(CCCCC2CCC3CCCCC23)CC1   \n",
       "2                   C1CCC(C2CCC3C(CCC4CCCCC43)C2)CC1   \n",
       "3             C1CCC(CCCCCC2CCC3C(CCC3C3CCCCC3)C2)CC1   \n",
       "4      C1CCC(C2CCC3CC4C(CC5CCC6CCCCC65)CCCC4CC32)CC1   \n",
       "\n",
       "                                                 mfp  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuclear_glucocor = loading_processing_data('nuclear_threshold_100nM_only_IC50','25_pic50.csv')\n",
    "#nuclear_glucocor.to_csv('data/input_data/glucocor_recep.csv', index_label = False)\n",
    "nuclear_glucocor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8317ee3d",
   "metadata": {},
   "source": [
    "## Split data to clusters and then create test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b3e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "456fddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomKMeans(KMeans):\n",
    "    def __init__(self, n_clusters=5, init='k-means++', \n",
    "                 n_init=10, max_iter=300, verbose=False,\n",
    "                 tol=1e-4, random_state=None, copy_x=True,algorithm='lloyd'\n",
    "                 ):\n",
    "        super().__init__(n_clusters=n_clusters, init=init,\n",
    "                         n_init=n_init, max_iter=max_iter, verbose=verbose,\n",
    "                         tol=tol, random_state=random_state, copy_x=copy_x,algorithm=algorithm)\n",
    "\n",
    "    def _transform(self, X):\n",
    "        return pairwise_distances(X, self.cluster_centers_, metric='wim metric')\n",
    "    \n",
    "\n",
    "def split_data_for_clusters(dff):\n",
    "    df = dff.drop_duplicates(subset='scaffolds_csk', keep=\"first\")\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df = df.drop(columns = ['index'])\n",
    "    \n",
    "    fps = [x for x in df['mfp']]\n",
    "\n",
    "    for x in range(1):\n",
    "        kmeans = CustomKMeans(n_clusters=5, random_state = 42)\n",
    "        kmeans.fit(fps)\n",
    "        print(\"Metrics: wim metric\")\n",
    "        print(kmeans.labels_)\n",
    "        name = 'cluster_' + f\"{x}\"\n",
    "        df[name] = kmeans.labels_\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5f1c0f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: wim metric\n",
      "[3 3 2 4 2 3 2 2 3 3 4 1 4 1 3 3 1 2 1 2 2 1 3 4 4 1 4 0 2 3 1 2 3 3 1 1 1\n",
      " 1 0 3 4 4 2 1 4 1 4 4 3 2 2 4 2 2 1 3 2 3 3 4 4 2 2 4 0 4 4 4 2 0 3 1 2 1\n",
      " 1 3 1 2 4 2 3 4 4 1 4 2 3 4 2 2 3 3 3 2 3 4 2 2 2 4 2 4 2 1 3 4 2 4 2 3 0\n",
      " 0 4 1 3 4 4 3 4 3 0 2 0 3 3 1 4 4 1 1 4 3 4 4 4 4 4 4 1 0 3 2 4 3 2 2 4 4\n",
      " 4 0 4 3 3 4 4 3 1 0 4 0 1 3 3 4 0 2 2 2 3 0 3 3 1 1 3 3 3 3 2 3 2 4 4 3 1\n",
      " 4 3 4 4 4 3 2 0 0 3 1 2 4 2 4 3 2 1 4 1 2]\n"
     ]
    }
   ],
   "source": [
    "split_data_for_clusters(nuclear_glucocor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e370b84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((134, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205), (167, 144), (178, 150, 191), (172,), (149, 27, 38))\n",
      "5\n",
      "((134, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205), (167, 144), (178, 150, 191), (172,), (149, 27, 38))\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "def tanimoto_distance_matrix(fp_list):\n",
    "    \"\"\"Calculate distance matrix for fingerprint list\"\"\"\n",
    "    dissimilarity_matrix = []\n",
    "    # Notice how we are deliberately skipping the first and last items in the list\n",
    "    # because we don't need to compare them against themselves\n",
    "    for i in range(1, len(fp_list)):\n",
    "        # Compare the current fingerprint against all the previous ones in the list\n",
    "        similarities = DataStructs.BulkTanimotoSimilarity(fp_list[i], fp_list[:i])\n",
    "        # Since we need a distance matrix, calculate 1-x for every element in similarity matrix\n",
    "        dissimilarity_matrix.extend([1 - x for x in similarities])\n",
    "    return dissimilarity_matrix\n",
    "\n",
    "def newTS(p1,p2):\n",
    "    p1=DataStructs.CreateFromBitString(\"\".join([str(p) for p in p1]))\n",
    "    p2=DataStructs.CreateFromBitString(\"\".join([str(p) for p in p2]))\n",
    "    return 1-DataStructs.TanimotoSimilarity(p1,p2)\n",
    "\n",
    "\n",
    "def split_data_for_clusters_(dff,cutoff):\n",
    "    df = dff.drop_duplicates(subset='scaffolds_csk', keep=\"first\")\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df = df.drop(columns = ['index'])    \n",
    "    fps = [x for x in df['mfp']]\n",
    "    # Now cluster the data with the implemented Butina algorithm:\n",
    "    clusters = Butina.ClusterData(fps, len(fps), cutoff,distFunc = newTS)\n",
    "    print(clusters)\n",
    "    print(len(clusters))\n",
    "    return\n",
    "\n",
    "def split_data_for_clusters_tsmatrix(dff,cutoff):\n",
    "    df = dff.drop_duplicates(subset='scaffolds_csk', keep=\"first\")\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df = df.drop(columns = ['index'])    \n",
    "    fps = [x for x in df['mfp']]\n",
    "\n",
    "    # Now cluster the data with the implemented Butina algorithm:\n",
    "    clusters = Butina.ClusterData(GetTanimotoDistMat(fps), len(fps), cutoff,isDistData=True)\n",
    "    print(clusters)\n",
    "    print(len(clusters))\n",
    "    return\n",
    "\n",
    "\n",
    "split_data_for_clusters_(nuclear_glucocor,cutoff=0.8)\n",
    "split_data_for_clusters_tsmatrix(nuclear_glucocor,cutoff=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c78acc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1 3 1 2 1 1 2 2 0 0 1 0 2 2 0 1 0 1 1 2 3 3 3 0 3 4 1 2 0 2 2 2 0 0 0\n",
      " 2 4 2 3 3 1 1 3 0 3 3 2 1 0 4 0 1 4 2 0 2 2 3 3 0 1 3 4 3 3 3 1 4 2 0 1 0\n",
      " 0 2 0 1 3 2 2 3 3 0 1 0 2 0 1 1 2 2 2 1 2 3 1 2 0 3 1 1 1 2 2 1 1 3 1 2 4\n",
      " 4 4 0 3 3 3 2 4 3 4 0 4 2 2 0 3 3 0 0 3 2 3 4 3 3 3 3 0 3 2 1 3 2 1 2 3 1\n",
      " 3 4 3 2 2 3 3 2 2 4 4 3 4 2 3 4 4 2 0 1 2 4 2 3 0 0 2 3 2 2 1 2 1 3 3 2 0\n",
      " 3 3 4 3 3 2 1 3 4 2 0 1 3 1 2 2 2 2 3 0 1]\n",
      "35\n",
      "38\n",
      "57\n",
      "54\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filv/anaconda3/envs/rdkit-env/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1975: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/filv/anaconda3/envs/rdkit-env/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1975: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_data_for_clusters_KMedoids(dff):\n",
    "    df = dff.drop_duplicates(subset='scaffolds_csk', keep=\"first\")\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df = df.drop(columns = ['index'])\n",
    "    \n",
    "    fps = [x for x in df['mfp']]\n",
    "\n",
    "    kmedoids = KMedoids(n_clusters=5,metric=\"jaccard\", random_state = 1, init='k-medoids++').fit(fps)\n",
    "    labels = kmedoids.labels_\n",
    "    print(labels)\n",
    "    print(len(labels[labels==0]))\n",
    "    print(len(labels[labels==1]))\n",
    "    print(len(labels[labels==2]))\n",
    "    print(len(labels[labels==3]))\n",
    "    print(len(labels[labels==4]))\n",
    "    return \n",
    "\n",
    "split_data_for_clusters_KMedoids(nuclear_glucocor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eeadb14b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'warnings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m     kmeans_instance\u001b[38;5;241m.\u001b[39mprocess()\n\u001b[1;32m     37\u001b[0m     clusters \u001b[38;5;241m=\u001b[39m kmeans_instance\u001b[38;5;241m.\u001b[39mget_clusters()\n\u001b[0;32m---> 39\u001b[0m \u001b[43msplit_data_for_clusters_ntlk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnuclear_glucocor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[75], line 30\u001b[0m, in \u001b[0;36msplit_data_for_clusters_ntlk\u001b[0;34m(dff)\u001b[0m\n\u001b[1;32m     28\u001b[0m amount_centers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     29\u001b[0m amount_candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m---> 30\u001b[0m initializer \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans_plusplus_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamount_centers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamount_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(initial_centers)\n\u001b[1;32m     32\u001b[0m start_centers \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m4.7\u001b[39m, \u001b[38;5;241m5.9\u001b[39m], [\u001b[38;5;241m5.7\u001b[39m, \u001b[38;5;241m6.5\u001b[39m]];\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/pyclustering/cluster/center_initializer.py:352\u001b[0m, in \u001b[0;36mkmeans_plusplus_initializer.initialize\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# For each next center\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__amount):\n\u001b[0;32m--> 352\u001b[0m     index_point \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_next_center\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     centers\u001b[38;5;241m.\u001b[39mappend(index_point)\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__free_indexes\u001b[38;5;241m.\u001b[39mremove(index_point)\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/pyclustering/cluster/center_initializer.py:251\u001b[0m, in \u001b[0;36mkmeans_plusplus_initializer.__get_next_center\u001b[0;34m(self, centers)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_next_center\u001b[39m(\u001b[38;5;28mself\u001b[39m, centers):\n\u001b[1;32m    241\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"!\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    @brief Calculates the next center for the data.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m \n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__calculate_shortest_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__candidates \u001b[38;5;241m==\u001b[39m kmeans_plusplus_initializer\u001b[38;5;241m.\u001b[39mFARTHEST_CENTER_CANDIDATE:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m index_point \u001b[38;5;129;01min\u001b[39;00m centers:\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/pyclustering/cluster/center_initializer.py:234\u001b[0m, in \u001b[0;36mkmeans_plusplus_initializer.__calculate_shortest_distances\u001b[0;34m(self, data, centers)\u001b[0m\n\u001b[1;32m    231\u001b[0m     dataset_differences[index_center] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39msum(numpy\u001b[38;5;241m.\u001b[39msquare(data \u001b[38;5;241m-\u001b[39m center), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m--> 234\u001b[0m     \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarnings\u001b[49m\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll-NaN (slice|axis) encountered\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    235\u001b[0m     shortest_distances \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mnanmin(dataset_differences, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m shortest_distances\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/numpy/__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'warnings'"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyclustering.cluster.kmeans import kmeans\n",
    "from pyclustering.utils.metric import type_metric, distance_metric\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.utils import read_sample\n",
    "from pyclustering.samples.definitions import FCPS_SAMPLES\n",
    "# Load list of points for cluster analysis.\n",
    "\n",
    "def user_function():\n",
    "    print(\"AAAA\")\n",
    "    p1=DataStructs.CreateFromBitString(\"\".join([str(p) for p in p1]))\n",
    "    p2=DataStructs.CreateFromBitString(\"\".join([str(p) for p in p2]))\n",
    "    return 1-DataStructs.TanimotoSimilarity(p1,p2)\n",
    "\n",
    "def split_data_for_clusters_ntlk(dff):\n",
    "\n",
    "\n",
    "    sample = read_sample(FCPS_SAMPLES.SAMPLE_TWO_DIAMONDS)\n",
    "    #print(sample)\n",
    "    data = [[0,1],[0,2],[0,4]]\n",
    "    \n",
    "    initial_centers = kmeans_plusplus_initializer(sample, 2).initialize()\n",
    "    amount_centers = 4\n",
    "    amount_candidates = 3\n",
    "    initializer = kmeans_plusplus_initializer(sample, amount_centers, amount_candidates).initialize()\n",
    "    print(initial_centers)\n",
    "    start_centers = [[4.7, 5.9], [5.7, 6.5]]\n",
    "     metric = distance_metric(type_metric.USER_DEFINED, func=user_function)\n",
    "    kmeans_instance = kmeans(sample, initial_centers)\n",
    "\n",
    "    # run cluster analysis and obtain results\n",
    "    kmeans_instance.process()\n",
    "    clusters = kmeans_instance.get_clusters()\n",
    "    \n",
    "split_data_for_clusters_ntlk(nuclear_glucocor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8fe872c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'warnings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m sample \u001b[38;5;241m=\u001b[39m read_sample(FCPS_SAMPLES\u001b[38;5;241m.\u001b[39mSAMPLE_TWO_DIAMONDS)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Prepare initial centers using K-Means++ method.\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m initial_centers \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans_plusplus_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create instance of K-Means algorithm with prepared centers.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m kmeans_instance \u001b[38;5;241m=\u001b[39m kmeans(sample, initial_centers)\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/pyclustering/cluster/center_initializer.py:352\u001b[0m, in \u001b[0;36mkmeans_plusplus_initializer.initialize\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# For each next center\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__amount):\n\u001b[0;32m--> 352\u001b[0m     index_point \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_next_center\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     centers\u001b[38;5;241m.\u001b[39mappend(index_point)\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__free_indexes\u001b[38;5;241m.\u001b[39mremove(index_point)\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/pyclustering/cluster/center_initializer.py:251\u001b[0m, in \u001b[0;36mkmeans_plusplus_initializer.__get_next_center\u001b[0;34m(self, centers)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_next_center\u001b[39m(\u001b[38;5;28mself\u001b[39m, centers):\n\u001b[1;32m    241\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"!\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    @brief Calculates the next center for the data.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m \n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__calculate_shortest_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__candidates \u001b[38;5;241m==\u001b[39m kmeans_plusplus_initializer\u001b[38;5;241m.\u001b[39mFARTHEST_CENTER_CANDIDATE:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m index_point \u001b[38;5;129;01min\u001b[39;00m centers:\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/pyclustering/cluster/center_initializer.py:234\u001b[0m, in \u001b[0;36mkmeans_plusplus_initializer.__calculate_shortest_distances\u001b[0;34m(self, data, centers)\u001b[0m\n\u001b[1;32m    231\u001b[0m     dataset_differences[index_center] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39msum(numpy\u001b[38;5;241m.\u001b[39msquare(data \u001b[38;5;241m-\u001b[39m center), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m--> 234\u001b[0m     \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarnings\u001b[49m\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll-NaN (slice|axis) encountered\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    235\u001b[0m     shortest_distances \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mnanmin(dataset_differences, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m shortest_distances\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/numpy/__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'warnings'"
     ]
    }
   ],
   "source": [
    "from pyclustering.cluster.kmeans import kmeans, kmeans_visualizer\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.samples.definitions import FCPS_SAMPLES\n",
    "from pyclustering.utils import read_sample\n",
    "# Load list of points for cluster analysis.\n",
    "sample = read_sample(FCPS_SAMPLES.SAMPLE_TWO_DIAMONDS)\n",
    "# Prepare initial centers using K-Means++ method.\n",
    "initial_centers = kmeans_plusplus_initializer(sample, 2).initialize()\n",
    "# Create instance of K-Means algorithm with prepared centers.\n",
    "kmeans_instance = kmeans(sample, initial_centers)\n",
    "# Run cluster analysis and obtain results.\n",
    "kmeans_instance.process()\n",
    "clusters = kmeans_instance.get_clusters()\n",
    "final_centers = kmeans_instance.get_centers()\n",
    "# Visualize obtained results\n",
    "kmeans_visualizer.show_clusters(sample, clusters, final_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4538dce8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'warnings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Prepare initial centers - amount of initial centers defines amount of clusters from which X-Means will\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# start analysis.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m amount_initial_centers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 10\u001b[0m initial_centers \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans_plusplus_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamount_initial_centers\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Create instance of X-Means algorithm. The algorithm will start analysis from 2 clusters, the maximum\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# number of clusters that can be allocated is 20.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m xmeans_instance \u001b[38;5;241m=\u001b[39m xmeans(sample, initial_centers, \u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/pyclustering/cluster/center_initializer.py:352\u001b[0m, in \u001b[0;36mkmeans_plusplus_initializer.initialize\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# For each next center\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__amount):\n\u001b[0;32m--> 352\u001b[0m     index_point \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_next_center\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     centers\u001b[38;5;241m.\u001b[39mappend(index_point)\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__free_indexes\u001b[38;5;241m.\u001b[39mremove(index_point)\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/pyclustering/cluster/center_initializer.py:251\u001b[0m, in \u001b[0;36mkmeans_plusplus_initializer.__get_next_center\u001b[0;34m(self, centers)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_next_center\u001b[39m(\u001b[38;5;28mself\u001b[39m, centers):\n\u001b[1;32m    241\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"!\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    @brief Calculates the next center for the data.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m \n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__calculate_shortest_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__candidates \u001b[38;5;241m==\u001b[39m kmeans_plusplus_initializer\u001b[38;5;241m.\u001b[39mFARTHEST_CENTER_CANDIDATE:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m index_point \u001b[38;5;129;01min\u001b[39;00m centers:\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/pyclustering/cluster/center_initializer.py:234\u001b[0m, in \u001b[0;36mkmeans_plusplus_initializer.__calculate_shortest_distances\u001b[0;34m(self, data, centers)\u001b[0m\n\u001b[1;32m    231\u001b[0m     dataset_differences[index_center] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39msum(numpy\u001b[38;5;241m.\u001b[39msquare(data \u001b[38;5;241m-\u001b[39m center), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m--> 234\u001b[0m     \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarnings\u001b[49m\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll-NaN (slice|axis) encountered\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    235\u001b[0m     shortest_distances \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mnanmin(dataset_differences, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m shortest_distances\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/numpy/__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'warnings'"
     ]
    }
   ],
   "source": [
    "from pyclustering.cluster import cluster_visualizer\n",
    "from pyclustering.cluster.xmeans import xmeans\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.utils import read_sample\n",
    "from pyclustering.samples.definitions import SIMPLE_SAMPLES\n",
    "sample = read_sample(SIMPLE_SAMPLES.SAMPLE_SIMPLE3)    \n",
    "# Prepare initial centers - amount of initial centers defines amount of clusters from which X-Means will\n",
    "# start analysis.\n",
    "amount_initial_centers = 2\n",
    "initial_centers = kmeans_plusplus_initializer(sample, amount_initial_centers).initialize()\n",
    "# Create instance of X-Means algorithm. The algorithm will start analysis from 2 clusters, the maximum\n",
    "# number of clusters that can be allocated is 20.\n",
    "xmeans_instance = xmeans(sample, initial_centers, 20)\n",
    "xmeans_instance.process()\n",
    "# Extract clustering results: clusters and their centers\n",
    "clusters = xmeans_instance.get_clusters()\n",
    "centers = xmeans_instance.get_centers()\n",
    "# Print total sum of metric errors\n",
    "print(\"Total WCE:\", xmeans_instance.get_total_wce())\n",
    "# Visualize clustering results\n",
    "visualizer = cluster_visualizer()\n",
    "visualizer.append_clusters(clusters, sample)\n",
    "visualizer.append_cluster(centers, None, marker='*', markersize=10)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "286ff10e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "split_data_for_clusters_() missing 1 required positional argument: 'cutoff'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [254], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_clusters_gluco \u001b[38;5;241m=\u001b[39m \u001b[43msplit_data_for_clusters_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnuclear_glucocor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#df_clusters_gluco.to_csv('data/input_data/glucocor_recp_split_to_clusters.csv',index_label = False)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df_clusters_gluco\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mTypeError\u001b[0m: split_data_for_clusters_() missing 1 required positional argument: 'cutoff'"
     ]
    }
   ],
   "source": [
    "df_clusters_gluco = split_data_for_clusters_(nuclear_glucocor)\n",
    "#df_clusters_gluco.to_csv('data/input_data/glucocor_recp_split_to_clusters.csv',index_label = False)\n",
    "df_clusters_gluco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1fb8a7fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cluster_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/rdkit-env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/rdkit-env/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/rdkit-env/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cluster_0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [123], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m df_clusters_gluco\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcluster_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m]))\n",
      "File \u001b[0;32m~/anaconda3/envs/rdkit-env/lib/python3.10/site-packages/pandas/core/frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/rdkit-env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cluster_0'"
     ]
    }
   ],
   "source": [
    "df = df_clusters_gluco\n",
    "print(len(df[df['cluster_0']==1]))\n",
    "print(len(df[df['cluster_1']==1]))\n",
    "print(len(df[df['cluster_2']==2]))\n",
    "print(len(df[df['cluster_3']==3]))\n",
    "print(len(df[df['cluster_4']==4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adce912",
   "metadata": {},
   "source": [
    "#### Data rozdeleni na shluky\n",
    "Rozdeleli jsme jednou a ulozili a ted natahujeme ty ulozene data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d539a3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molregno</th>\n",
       "      <th>stand_type</th>\n",
       "      <th>pchembl_value</th>\n",
       "      <th>stand_value</th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>stand_inchi</th>\n",
       "      <th>chembl_id</th>\n",
       "      <th>tid</th>\n",
       "      <th>pref_name</th>\n",
       "      <th>scaffolds_csk</th>\n",
       "      <th>mfp</th>\n",
       "      <th>cluster_0</th>\n",
       "      <th>cluster_1</th>\n",
       "      <th>cluster_2</th>\n",
       "      <th>cluster_3</th>\n",
       "      <th>cluster_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>557956</td>\n",
       "      <td>IC50</td>\n",
       "      <td>7.85</td>\n",
       "      <td>14.0</td>\n",
       "      <td>C[C@H]1C[C@@H]2[C@H]3CCC4=CC(=O)C=C[C@@]4(C)[C...</td>\n",
       "      <td>PENABDXTRKXMIW-PZVMULSCSA-N</td>\n",
       "      <td>CHEMBL540936</td>\n",
       "      <td>25</td>\n",
       "      <td>Glucocorticoid receptor</td>\n",
       "      <td>C(CCCCCCC1CCC2C1CCC1C3CCCCC3CCC21)CCCCCC1CCC(C...</td>\n",
       "      <td>&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVec...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1607842</td>\n",
       "      <td>IC50</td>\n",
       "      <td>8.70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CC[C@@H](Cn1ccc2ccccc21)NS(=O)(=O)c1c(N)cc(Cl)...</td>\n",
       "      <td>RXEIQMFFHIVGLD-AWEZNQCLSA-N</td>\n",
       "      <td>CHEMBL3093461</td>\n",
       "      <td>25</td>\n",
       "      <td>Glucocorticoid receptor</td>\n",
       "      <td>C1CCC(CCCCC2CCC3CCCCC23)CC1</td>\n",
       "      <td>&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVec...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1841315</td>\n",
       "      <td>IC50</td>\n",
       "      <td>7.38</td>\n",
       "      <td>22.0</td>\n",
       "      <td>CC[C@@]12C[C@@](C)(O)[C@](O)(c3cccnc3)C[C@H]1C...</td>\n",
       "      <td>KDUBEHWLJHNXHQ-XUFNMVPLSA-N</td>\n",
       "      <td>CHEMBL3421877</td>\n",
       "      <td>25</td>\n",
       "      <td>Glucocorticoid receptor</td>\n",
       "      <td>C1CCC(C2CCC3C(CCC4CCCCC43)C2)CC1</td>\n",
       "      <td>&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVec...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2172692</td>\n",
       "      <td>IC50</td>\n",
       "      <td>7.01</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Cc1cc(C)c(S(=O)(=O)N[C@@H](C)COc2ccc3c(cnn3-c3...</td>\n",
       "      <td>LREULHCSPAWXMB-IBGZPJMESA-N</td>\n",
       "      <td>CHEMBL3963321</td>\n",
       "      <td>25</td>\n",
       "      <td>Glucocorticoid receptor</td>\n",
       "      <td>C1CCC(CCCCCC2CCC3C(CCC3C3CCCCC3)C2)CC1</td>\n",
       "      <td>&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVec...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>325089</td>\n",
       "      <td>IC50</td>\n",
       "      <td>8.29</td>\n",
       "      <td>5.1</td>\n",
       "      <td>C[C@]12Cc3cnn(-c4ccc(F)cc4)c3C=C1CCC[C@@H]2[C@...</td>\n",
       "      <td>GSBXDPQKEHNRQR-NPAAKHOSSA-N</td>\n",
       "      <td>CHEMBL363179</td>\n",
       "      <td>25</td>\n",
       "      <td>Glucocorticoid receptor</td>\n",
       "      <td>C1CCC(C2CCC3CC4C(CC5CCC6CCCCC65)CCCC4CC32)CC1</td>\n",
       "      <td>&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVec...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   molregno stand_type  pchembl_value  stand_value  \\\n",
       "0    557956       IC50           7.85         14.0   \n",
       "1   1607842       IC50           8.70          2.0   \n",
       "2   1841315       IC50           7.38         22.0   \n",
       "3   2172692       IC50           7.01         98.0   \n",
       "4    325089       IC50           8.29          5.1   \n",
       "\n",
       "                                    canonical_smiles  \\\n",
       "0  C[C@H]1C[C@@H]2[C@H]3CCC4=CC(=O)C=C[C@@]4(C)[C...   \n",
       "1  CC[C@@H](Cn1ccc2ccccc21)NS(=O)(=O)c1c(N)cc(Cl)...   \n",
       "2  CC[C@@]12C[C@@](C)(O)[C@](O)(c3cccnc3)C[C@H]1C...   \n",
       "3  Cc1cc(C)c(S(=O)(=O)N[C@@H](C)COc2ccc3c(cnn3-c3...   \n",
       "4  C[C@]12Cc3cnn(-c4ccc(F)cc4)c3C=C1CCC[C@@H]2[C@...   \n",
       "\n",
       "                   stand_inchi      chembl_id  tid                 pref_name  \\\n",
       "0  PENABDXTRKXMIW-PZVMULSCSA-N   CHEMBL540936   25  Glucocorticoid receptor    \n",
       "1  RXEIQMFFHIVGLD-AWEZNQCLSA-N  CHEMBL3093461   25  Glucocorticoid receptor    \n",
       "2  KDUBEHWLJHNXHQ-XUFNMVPLSA-N  CHEMBL3421877   25  Glucocorticoid receptor    \n",
       "3  LREULHCSPAWXMB-IBGZPJMESA-N  CHEMBL3963321   25  Glucocorticoid receptor    \n",
       "4  GSBXDPQKEHNRQR-NPAAKHOSSA-N   CHEMBL363179   25  Glucocorticoid receptor    \n",
       "\n",
       "                                       scaffolds_csk  \\\n",
       "0  C(CCCCCCC1CCC2C1CCC1C3CCCCC3CCC21)CCCCCC1CCC(C...   \n",
       "1                        C1CCC(CCCCC2CCC3CCCCC23)CC1   \n",
       "2                   C1CCC(C2CCC3C(CCC4CCCCC43)C2)CC1   \n",
       "3             C1CCC(CCCCCC2CCC3C(CCC3C3CCCCC3)C2)CC1   \n",
       "4      C1CCC(C2CCC3CC4C(CC5CCC6CCCCC65)CCCC4CC32)CC1   \n",
       "\n",
       "                                                 mfp  cluster_0  cluster_1  \\\n",
       "0  <rdkit.DataStructs.cDataStructs.ExplicitBitVec...          1          1   \n",
       "1  <rdkit.DataStructs.cDataStructs.ExplicitBitVec...          1          1   \n",
       "2  <rdkit.DataStructs.cDataStructs.ExplicitBitVec...          2          0   \n",
       "3  <rdkit.DataStructs.cDataStructs.ExplicitBitVec...          0          2   \n",
       "4  <rdkit.DataStructs.cDataStructs.ExplicitBitVec...          2          0   \n",
       "\n",
       "   cluster_2  cluster_3  cluster_4  \n",
       "0          2          3          4  \n",
       "1          2          3          4  \n",
       "2          0          1          0  \n",
       "3          1          1          2  \n",
       "4          0          1          2  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nuclear_glucocor = pd.read_csv('data/input_data/glucocor_recep.csv')\n",
    "nuclear_glucocor.head()\n",
    "data_clusters_glucocor = pd.read_csv(\"data/input_data/glucocor_recp_split_to_clusters.csv\")\n",
    "data_clusters_glucocor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "56162109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_clusters_glucocor[data_clusters_glucocor['cluster_1']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54704411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chemble_id_for_train_test_sets_dis(data_target,data_cluters, tran, test, cluster):\n",
    "\n",
    "    input_id_Molpher_tran_nepodobne = []\n",
    "    input_id_tran_nepodobne = []\n",
    "    input_id_test_nepodobne = []\n",
    "    \n",
    "    count = 0\n",
    "    for r in tran:\n",
    "        nazev = \"cluster_\" + f\"{cluster}\"\n",
    "        a = data_cluters[data_cluters[nazev]==r]\n",
    "        for x in a.index:\n",
    "            smiles = a['scaffolds_csk'].loc[x]\n",
    "            b = data_target[data_target['scaffolds_csk']==smiles]\n",
    "            b = b.sort_values(by=['stand_value'])    \n",
    "            input_id_Molpher_tran_nepodobne.append(b['chembl_id'].iloc[:1].item())\n",
    "            for y in b.index:\n",
    "                input_id_tran_nepodobne.append(b['chembl_id'].loc[y])\n",
    "    #testovaci_data_target\n",
    "    nazev = \"cluster_\" + f\"{cluster}\"\n",
    "    a = data_cluters[data_cluters[nazev]==r]\n",
    "    for x in a.index:\n",
    "        smiles = a['scaffolds_csk'].loc[x]\n",
    "        b = data_target[data_target['scaffolds_csk']==smiles]\n",
    "        b = b.sort_values(by=['stand_value'])    \n",
    "        for y in b.index:\n",
    "            input_id_test_nepodobne.append(b['chembl_id'].loc[y])\n",
    "    \n",
    "    \n",
    "    print(\"Set size for train set for Molpher:\",len(input_id_Molpher_tran_nepodobne))\n",
    "    print(\"Set size fot train set for other generators:\",len(input_id_tran_nepodobne))\n",
    "    print(\"Set size for test set:\",len(input_id_test_nepodobne))\n",
    "    return input_id_Molpher_tran_nepodobne,input_id_tran_nepodobne, input_id_test_nepodobne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "637a03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sets_for_Molpher(df, data):\n",
    "    dff = pd.DataFrame(columns = ['start_id','stop_id','start_smiles','stop_smiles'])\n",
    "    a = list(itertools.permutations(df,2))\n",
    "    for x in a:\n",
    "        start_id = x[0]\n",
    "        stop_id = x[1]\n",
    "        start_smiles = data[data['chembl_id']==start_id]\\\n",
    "                        ['canonical_smiles'].item()\n",
    "        stop_smiles = data[data['chembl_id']==stop_id]\\\n",
    "                        ['canonical_smiles'].item()\n",
    "        dff.loc[len(dff)] = [start_id,stop_id,start_smiles,stop_smiles]\n",
    "    dff['id'] = [x for x in range(len(dff))]\n",
    "    new_columns = ['id','start_id','stop_id','start_smiles','stop_smiles']\n",
    "    dff = dff[new_columns]\n",
    "    \n",
    "    return dff\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f07a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sets_for_other_gen_tran_and_test(df, data):\n",
    "    dff = pd.DataFrame(columns = ['chembl_id','smiles'])\n",
    "    for x in df:\n",
    "        chembl_id = x        \n",
    "        smiles = data[data['chembl_id']==chembl_id]\\\n",
    "                        ['canonical_smiles'].item()\n",
    "        \n",
    "        dff.loc[len(dff)] = [chembl_id,smiles]\n",
    "    dff['id'] = [x for x in range(len(dff))]\n",
    "    new_columns = ['id','chembl_id','smiles']\n",
    "    dff = dff[new_columns]\n",
    "    \n",
    "    return dff\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e6f0b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_to_train_test_dis(data_target,data_clusters):\n",
    "    \n",
    "    for x in ([[1,2,3,4],0,0],[[0,2,3,4],1,1],[[0,1,3,4],2,2],[[0,1,2,4],3,3],[[0,1,2,3],4,4]):\n",
    "        name = []\n",
    "        input_id_Molpher_train,input_id_gen_train,input_id_test = chemble_id_for_train_test_sets_dis\\\n",
    "                    (data_target,data_clusters,x[0],x[1],x[2])\n",
    "        input_Molpher_train = sets_for_Molpher(input_id_Molpher_train, data_target)\n",
    "        input_gener_train = sets_for_other_gen_tran_and_test\\\n",
    "                        (input_id_gen_train,data_target)\n",
    "        input_test = sets_for_other_gen_tran_and_test\\\n",
    "                        (input_id_test,data_target)\n",
    "        \n",
    "        \n",
    "        input_Molpher_train.to_csv(f\"data/input_data/input_Molpher_glucocor_dis_{x[2]}.csv\", index=False)\n",
    "        input_gener_train.to_csv(f\"data/input_data/input_gener_glucocor_dis_{x[2]}.csv\", index=False)\n",
    "        input_test.to_csv(f\"data/input_data/input_test_glucocor_dis_{x[2]}.csv\",  index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ab8a0",
   "metadata": {},
   "source": [
    "### Create sets for exploration control, name of sets have sufix _dis_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d3354b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set size for train set for Molpher: 169\n",
      "Set size fot train set for other generators: 986\n",
      "Set size for test set: 190\n",
      "Set size for train set for Molpher: 151\n",
      "Set size fot train set for other generators: 861\n",
      "Set size for test set: 71\n",
      "Set size for train set for Molpher: 155\n",
      "Set size fot train set for other generators: 867\n",
      "Set size for test set: 291\n",
      "Set size for train set for Molpher: 153\n",
      "Set size fot train set for other generators: 858\n",
      "Set size for test set: 172\n",
      "Set size for train set for Molpher: 158\n",
      "Set size fot train set for other generators: 891\n",
      "Set size for test set: 244\n"
     ]
    }
   ],
   "source": [
    "split_data_to_train_test_dis(nuclear_glucocor,data_clusters_glucocor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a291615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b333e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8c7f987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/input_data/glucocor_recp_split_to_clusters.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "be17bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame()\n",
    "for x in range(5):\n",
    "    name = 'cluster_' + str(x)\n",
    "    zero = len(df[df[name]==0])\n",
    "    one = len(df[df[name]==1])\n",
    "    two = len(df[df[name]==2])\n",
    "    three = len(df[df[name]==3])\n",
    "    four = len(df[df[name]==4])\n",
    "    dff[x] = [zero,one,two,three,four]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a954c125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>71</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>31</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>27</td>\n",
       "      <td>51</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>53</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>47</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4\n",
       "0  37  71  46  13  52\n",
       "1  56  55  31  69  13\n",
       "2  71  27  51  39  50\n",
       "3  12  38  31  53  43\n",
       "4  30  15  47  32  48"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d5524e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
